{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import faiss \n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.io import mmread\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TripletMarginLoss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.optim as optim\n",
    "# from sklearn.cluster import KMeans\n",
    "# import torch_geometric.utils as pyg_utils\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# import pandas as pd\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check cuda \n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Compute Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / 1e9} GB\")\n",
    "    print(f\"Memory Cached: {torch.cuda.memory_reserved(0) / 1e9} GB\")\n",
    "else:\n",
    "    print(\"No CUDA-compatible GPU found.\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = mmread('scRNA.mtx')\n",
    "coo_matrix = rawData.tocoo()\n",
    "print(coo_matrix)\n",
    "print(coo_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process And Modify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split_data(coo_matrix, max_number):\n",
    "    #get only non-zero values\n",
    "    total_nnz = coo_matrix.nnz \n",
    "\n",
    "    # Ensure max_nnz doesnâ€™t exceed total\n",
    "    if max_number >= total_nnz:\n",
    "        raise ValueError(f\"max_nnz ({max_number}) must be less than total non-zero elements ({total_nnz})\")\n",
    "    \n",
    "    rows = coo_matrix.row\n",
    "    cols = coo_matrix.col\n",
    "    data = coo_matrix.data\n",
    "    \n",
    "    selected_indices = np.arange(max_number)  \n",
    "\n",
    "    selected = coo_matrix.__class__(\n",
    "        (data[selected_indices], (rows[selected_indices], cols[selected_indices])),\n",
    "        shape=coo_matrix.shape\n",
    "    )\n",
    "    \n",
    "    return selected\n",
    "\n",
    "processed_data = clean_and_split_data(coo_matrix=coo_matrix, max_number=900000)\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph Data Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_graph(data, threshold):\n",
    "\n",
    "    gene_expression = data.data\n",
    "    \n",
    "    x = np.asarray(gene_expression, dtype=np.float32)\n",
    "    x = x.reshape(-1, 1)\n",
    "\n",
    "\n",
    "    gpu_resource_manager = faiss.StandardGpuResources() \n",
    "    similarity_object = faiss.IndexFlatL2(1)\n",
    "    similarity_object_in_gpu = faiss.index_cpu_to_gpu(gpu_resource_manager, 0, similarity_object)\n",
    "\n",
    "\n",
    "    print(similarity_object_in_gpu.is_trained)  \n",
    "    print(f\"FAISS index type: {type(similarity_object_in_gpu)}\") \n",
    "\n",
    "\n",
    "    similarity_object_in_gpu.add(x)\n",
    "    k=2\n",
    "    distances, indices = similarity_object_in_gpu.search(x, k + 1)\n",
    "    \n",
    "    edge_index_list = []\n",
    "    outliers = []\n",
    "    \n",
    "    for i in range(len(gene_expression)):\n",
    "        nearest_neighbors = indices[i, 1:k+1]  \n",
    "        neighbor_distances = distances[i, 1:k+1]\n",
    "        \n",
    "        for j, dist in zip(nearest_neighbors, neighbor_distances):\n",
    "            if dist <= threshold ** 2:\n",
    "                edge_index_list.append((i, j))\n",
    "            else:\n",
    "                outliers.append(int(j))\n",
    "    \n",
    "\n",
    "    edge_index_np = np.array(edge_index_list).T\n",
    "    edge_index = torch.tensor(edge_index_np, dtype=torch.long) if edge_index_np.size > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    cleaned_outliers = list(set(outliers))\n",
    "    print(cleaned_outliers)\n",
    "\n",
    "    x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "    pyg_data = Data(edge_index=edge_index, x=x_tensor)\n",
    "    print(pyg_data)\n",
    "    return pyg_data\n",
    "\n",
    "data = cell_graph(data=processed_data,threshold=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_lvl = data.x.cpu().numpy()\n",
    "\n",
    "k = 10  \n",
    "d = gene_expression_lvl.shape[1] \n",
    "kmeans = faiss.Kmeans(d, k, niter=300, gpu=True)  \n",
    "\n",
    "\n",
    "kmeans.train(gene_expression_lvl)\n",
    "\n",
    "_, labels = kmeans.index.search(gene_expression_lvl, 1) \n",
    "labels = labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = np.bincount(labels)  \n",
    "\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"Cluster {i}: {cluster_counts[i]} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_levels = data.x.cpu().numpy().flatten() \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "\n",
    "for label in unique_labels:\n",
    "    cluster_cells = gene_expression_lvl[labels == label]\n",
    "    num_cells = len(cluster_cells)\n",
    "    plt.scatter(np.full_like(cluster_cells, label), cluster_cells, alpha=0.5, label=f'Cluster {label} ({num_cells} cells)')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('Gene Expression Level')\n",
    "plt.title('Gene Expression Levels per Cluster')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_levels_cpu = gene_expression_levels.cpu().numpy() if hasattr(gene_expression_levels, \"cpu\") else gene_expression_levels\n",
    "num_cells = len(gene_expression_levels_cpu)\n",
    "\n",
    "cell_indices = np.arange(num_cells)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(gene_expression_levels_cpu, cell_indices, alpha=0.5, s=2, c='blue')  \n",
    "\n",
    "plt.xlabel('Gene Expression Level')\n",
    "plt.ylabel('Cell Index')\n",
    "plt.title('Gene Expression Levels Across Cells')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(gene_expression_levels_cpu, cell_indices, c=labels, cmap='tab10', alpha=0.5, s=2)\n",
    "plt.xlabel('Gene Expression Level')\n",
    "plt.ylabel('Cell Index')\n",
    "plt.title('Gene Expression Levels Across Cells (Colored by Cluster)')\n",
    "plt.colorbar(label='Cluster ID')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))  \n",
    "        \n",
    "        for _ in range(num_layers - 2):  \n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))  \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]: \n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index) \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traning Without Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train without loss function\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "model = GraphSAGE(in_channels=1, hidden_channels=128, out_channels=64, num_layers=2).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model(data.x, data.edge_index)\n",
    "\n",
    "print(embeddings.shape)\n",
    "\n",
    "torch.save(model, 'entire_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_np = embeddings.cpu().numpy()\n",
    "\n",
    "d = embeddings_np.shape[1]  \n",
    "k = 10\n",
    "kmeans = faiss.Kmeans(d, k, niter=300, gpu=True)  \n",
    "\n",
    "\n",
    "kmeans.train(embeddings_np)\n",
    "_, labels = kmeans.index.search(embeddings_np, 1)\n",
    "\n",
    "\n",
    "labels = torch.tensor(labels.flatten(), device='cuda')\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = torch.bincount(labels)\n",
    "\n",
    "# Print the number of cells in each cluster\n",
    "for i, count in enumerate(cluster_counts):\n",
    "    print(f\"Cluster {i}: {count.item()} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cpu = labels.cpu().numpy()\n",
    "gene_expression_levels_cpu = gene_expression_levels\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique_labels = np.unique(labels_cpu)\n",
    "\n",
    "for label in unique_labels:\n",
    "    cluster_cells = gene_expression_levels_cpu[labels_cpu == label]\n",
    "    num_cells = len(cluster_cells)\n",
    "    plt.scatter(np.full_like(cluster_cells, label), cluster_cells, alpha=0.5, label=f'Cluster {label} ({num_cells} cells)')\n",
    "\n",
    "\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('Gene Expression Level')\n",
    "plt.title('Gene Expression Levels per Cluster')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_levels_cpu = gene_expression_levels.cpu().numpy() if hasattr(gene_expression_levels, \"cpu\") else gene_expression_levels\n",
    "num_cells = len(gene_expression_levels_cpu)\n",
    "\n",
    "cell_indices = np.arange(num_cells)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(gene_expression_levels_cpu, cell_indices, alpha=0.5, s=2, c='blue')  \n",
    "\n",
    "plt.xlabel('Gene Expression Level')\n",
    "plt.ylabel('Cell Index')\n",
    "plt.title('Gene Expression Levels Across Cells')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(gene_expression_levels_cpu, cell_indices, c=labels_cpu, cmap='tab10', alpha=0.5, s=2)\n",
    "plt.xlabel('Gene Expression Level')\n",
    "plt.ylabel('Cell Index')\n",
    "plt.title('Gene Expression Levels Across Cells (Colored by Cluster)')\n",
    "plt.colorbar(label='Cluster ID')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Reserved : {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "print(f\"Max Allocated: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Max Reserved : {torch.cuda.max_memory_reserved() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1  + Testing with parameter changes - No Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = GraphSAGE(in_channels=1, hidden_channels=64,out_channels=64, num_layers=4).to(device)\n",
    "model1_1 = GraphSAGE(in_channels=1, hidden_channels=64,out_channels=64, num_layers=8).to(device)\n",
    "model1_2 = GraphSAGE(in_channels=1, hidden_channels=64,out_channels=64, num_layers=16).to(device)\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings_model1 = model1(data.x, data.edge_index)\n",
    "\n",
    "print(embeddings_model1.shape)\n",
    "\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings_model1_1 = model1_1(data.x, data.edge_index)\n",
    "\n",
    "print(embeddings_model1_1.shape)\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings_model1_2 = model1_2(data.x, data.edge_index)\n",
    "\n",
    "print(embeddings_model1_2.shape)\n",
    "\n",
    "\n",
    "torch.save(model1, 'entire_model1.pth')\n",
    "torch.save(model1_1, 'entire_model1_1.pth')\n",
    "torch.save(model1_2, 'entire_model1_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 with +loss function - Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets_with_faiss_gpu(embeddings, k=5, num_triplets_per_node=1):\n",
    "    device = embeddings.device\n",
    "    emb_np = embeddings.detach().cpu().numpy().astype('float32')\n",
    "    num_nodes, emb_dim = emb_np.shape\n",
    "\n",
    "    index = faiss.IndexFlatL2(emb_dim)\n",
    "    if torch.cuda.is_available():\n",
    "        res = faiss.StandardGpuResources()\n",
    "        index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    index.add(emb_np)\n",
    "\n",
    "    _, neighbors = index.search(emb_np, k + 1)\n",
    "\n",
    "    anchors, positives, negatives = [], [], []\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        pos_candidates = neighbors[i][1:]  # Exclude self\n",
    "        for _ in range(num_triplets_per_node):\n",
    "            pos_idx = random.choice(pos_candidates)\n",
    "\n",
    "            # Avoid large k\n",
    "            k_neg = min(50, num_nodes)\n",
    "            _, all_indices = index.search(emb_np[i:i+1], k_neg)\n",
    "\n",
    "            hard_neg = None\n",
    "            for n in all_indices[0][1:]:\n",
    "                if n not in neighbors[i]:\n",
    "                    hard_neg = n\n",
    "                    break\n",
    "\n",
    "            if hard_neg is not None:\n",
    "                anchors.append(i)\n",
    "                positives.append(pos_idx)\n",
    "                negatives.append(hard_neg)\n",
    "\n",
    "    anchor = embeddings[anchors].to(device)\n",
    "    positive = embeddings[positives].to(device)\n",
    "    negative = embeddings[negatives].to(device)\n",
    "\n",
    "    return anchor, positive, negative\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_loss_fn = TripletMarginLoss(margin=0.5, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = GraphSAGE(in_channels=1, hidden_channels=8, out_channels=4, num_layers=2).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model3.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    embeddings = model3(data.x, data.edge_index)\n",
    "\n",
    "    anchor, positive, negative = generate_triplets_with_faiss_gpu(embeddings, k=5)\n",
    "    \n",
    "    loss = triplet_loss_fn(anchor, positive, negative)\n",
    "\n",
    "    #distance logging\n",
    "    pos_dist = F.pairwise_distance(anchor, positive, p=2)\n",
    "    neg_dist = F.pairwise_distance(anchor, negative, p=2)\n",
    "\n",
    "    avg_pos_dist = pos_dist.mean().item()\n",
    "    avg_neg_dist = neg_dist.mean().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f} | PosDist: {avg_pos_dist:.4f} | NegDist: {avg_neg_dist:.4f}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings_model3 = model1_2(data.x, data.edge_index)\n",
    "\n",
    "print(embeddings_model3.shape)\n",
    "\n",
    "\n",
    "torch.save(model3, 'entire_model3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4 +loss function - Constrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with constrative-loss \n",
    "def generate_contrastive_pairs_faiss_gpu(embeddings, k=3, num_negatives=1):\n",
    "    \"\"\"\n",
    "    Generate (i, j, y) pairs for contrastive loss using FAISS on GPU.\n",
    "\n",
    "    Args:\n",
    "        embeddings: Tensor [num_nodes, emb_dim] on GPU.\n",
    "        k: # of nearest neighbors (positives).\n",
    "        num_negatives: # of negative samples per node.\n",
    "\n",
    "    Returns:\n",
    "        anchor_idx, pair_idx, labels (1 for positive, 0 for negative)\n",
    "    \"\"\"\n",
    "    device = embeddings.device\n",
    "    emb_np = embeddings.detach().cpu().numpy().astype('float32')\n",
    "    num_nodes = emb_np.shape[0]\n",
    "\n",
    "    index = faiss.IndexFlatL2(emb_np.shape[1])\n",
    "    if torch.cuda.is_available():\n",
    "        res = faiss.StandardGpuResources()\n",
    "        index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    index.add(emb_np)\n",
    "    _, neighbors = index.search(emb_np, k + 1)\n",
    "\n",
    "    anchor_idx, pair_idx, labels = [], [], []\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        # Positive pairs from neighbors (skip self)\n",
    "        for j in neighbors[i][1:]:\n",
    "            anchor_idx.append(i)\n",
    "            pair_idx.append(j)\n",
    "            labels.append(1)\n",
    "\n",
    "        # Negative samples (not among k neighbors)\n",
    "        for _ in range(num_negatives):\n",
    "            j = random.randint(0, num_nodes - 1)\n",
    "            while j in neighbors[i]:\n",
    "                j = random.randint(0, num_nodes - 1)\n",
    "            anchor_idx.append(i)\n",
    "            pair_idx.append(j)\n",
    "            labels.append(0)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(anchor_idx, device=device),\n",
    "        torch.tensor(pair_idx, device=device),\n",
    "        torch.tensor(labels, dtype=torch.float32, device=device),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_fn(z_i, z_j, y, margin=2.0):\n",
    "    \"\"\"\n",
    "    Contrastive loss: minimize distance for positives, maximize for negatives.\n",
    "    \"\"\"\n",
    "    dist = F.pairwise_distance(z_i, z_j)\n",
    "    loss = y * dist.pow(2) + (1 - y) * F.relu(margin - dist).pow(2)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = GraphSAGE(in_channels=1, hidden_channels=8, out_channels=4, num_layers=4).to(device)\n",
    "\n",
    "model4.train()\n",
    "for epoch in range(100):  \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    embeddings = model4(data.x, data.edge_index)\n",
    "\n",
    "    anchor_idx, pair_idx, labels = generate_contrastive_pairs_faiss_gpu(embeddings, k=5)\n",
    "\n",
    "    z_i = embeddings[anchor_idx]\n",
    "    z_j = embeddings[pair_idx]\n",
    "\n",
    "    loss = contrastive_loss_fn(z_i, z_j, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings_model4 = model1_2(data.x, data.edge_index)\n",
    "\n",
    "print(embeddings_model4.shape)\n",
    "\n",
    "\n",
    "torch.save(model4, 'entire_model4.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRareCellDetect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
